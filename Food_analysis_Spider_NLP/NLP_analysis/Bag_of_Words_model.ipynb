{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words model\n",
    "Bag of words model is one of a series of techniques from a field of computer science known as Natural Language Processing or NLP to extract features from text. \n",
    "- This model extracts features from text in the form of frequency counts\n",
    "- The way it does this is by **counting the frequency of words** in a document.\n",
    "\n",
    "Input:\n",
    "1. vocabulary\n",
    "2. documents/sentences\n",
    "\n",
    "The output of the bag of words model is a **frequency vector**.\n",
    "\n",
    "\n",
    "### Motivation\n",
    "Trying to implement a machine learning algorithm to classify documents. For example, classify spam or non-spam email.\n",
    "\n",
    "\n",
    "1. Word proportion\n",
    "2. Raw word counts\n",
    "3. Binary (1 if appear)\n",
    "4. TF-IDF \n",
    "5. feature vectors\n",
    "\n",
    "\n",
    "Reference:\n",
    "\n",
    "http://www.insightsbot.com/blog/R8fu5/bag-of-words-algorithm-in-python-introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1: defining the vocabulary and create frequency vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Machine learning is great\",\"Natural Language Processing is a complex field\",\"Natural Language Processing is used in machine learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. extract the words from a document using regular expressions\n",
    "2. convert all words to lower case and exclude our stop words.\n",
    "\"\"\"\n",
    "def extract_words(sentence):\n",
    "    ignore_words = ['a']\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split() #nltk.word_tokenize(sentence)\n",
    "    words_cleaned = [w.lower() for w in words if w not in ignore_words]\n",
    "    return words_cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "builds our vocabulary by looping through all our documents (sentences), \n",
    "extracting the words from each, removing duplicates using the set function \n",
    "\n",
    "Return\n",
    "-------\n",
    "a sorted list of words.\n",
    "\"\"\"\n",
    "def tokenize_sentences(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        w = extract_words(sentence)\n",
    "        words.extend(w)\n",
    "        \n",
    "    words = sorted(list(set(words)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert sentences into a frequency vector \n",
    "The result is a numerical vector which can be utilized as inputs in the various machine learning algorithms to classify documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stage 1:\n",
    "implementation of the bag of words model\n",
    "takes an input of a sentence and words (our vocabulary). \n",
    "It then extracts the words from the input sentence using the previously defined function. \n",
    "a vector of zeros using numpy zeros function with a length of the number of words in our vocabulary.\n",
    "\n",
    "Stage 2: \n",
    "for each word in our sentence, we loop through our vocabulary and if the word exists we increase the count by 1. \n",
    "We return the numpy array of frequency counts.\n",
    "\"\"\"\n",
    "\n",
    "def bagofwords(sentence, words):\n",
    "    #Stage 1:\n",
    "    sentence_words = extract_words(sentence)\n",
    "    bag = np.zeros(len(words)) # frequency word count\n",
    "    # stage 2:\n",
    "    for sw in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word == sw: \n",
    "                bag[i] += 1\n",
    "                \n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_vector = bagofwords(\"Machine learning is great\", vocabulary)\n",
    "frequency_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Sentences using SciKit Learn CountVectorizer\n",
    "SciKit Learn CountVectorizer:\n",
    "Python’s SciKit-Learn provides built in functions to implement the above bag of words model. \n",
    "\n",
    "Let’s implement all the above in simply 4 lines of code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "sentences = [\"Machine learning is great\",\"Natural Language Processing is a complex field\",\"Natural Language Processing is used in machine learning\"]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 5000) \n",
    "# create vocabulary\n",
    "train_data_features = vectorizer.fit_transform(sentences)\n",
    "# create frequency vector\n",
    "vectorizer.transform([\"Machine learning is great\"]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
